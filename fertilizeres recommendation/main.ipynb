{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afddda00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31da05f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv(\"fertilizer_dataset_cleaned.csv\")\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a76bc450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in dataset: 300\n",
      "Train and Test split done successfully!\n",
      "Train rows: 240\n",
      "Test rows: 60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"fertilizer_dataset_cleaned.csv\")\n",
    "\n",
    "# Display basic info\n",
    "print(\"Total rows in dataset:\", len(data))\n",
    "\n",
    "# Split the data (80% train, 20% test)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the datasets\n",
    "train_data.to_csv(\"train.csv\", index=False)\n",
    "test_data.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "print(\"Train and Test split done successfully!\")\n",
    "print(\"Train rows:\", len(train_data))\n",
    "print(\"Test rows:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bde5989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing train.csv and test.csv ...\n",
      "Train shape: (240, 9)\n",
      "Test shape: (60, 9)\n",
      "Training RandomForestClassifier ...\n",
      "\n",
      "Test Accuracy: 0.9333\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    10-26-26       0.00      0.00      0.00         1\n",
      "    14-35-14       0.71      1.00      0.83         5\n",
      "    17-17-17       1.00      0.86      0.92         7\n",
      "     28-28-0       1.00      1.00      1.00         4\n",
      "         DAP       1.00      1.00      1.00        16\n",
      "         MOP       1.00      0.75      0.86         8\n",
      "        Urea       0.90      1.00      0.95        19\n",
      "\n",
      "    accuracy                           0.93        60\n",
      "   macro avg       0.80      0.80      0.79        60\n",
      "weighted avg       0.93      0.93      0.93        60\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  1  0  0  0  0  0]\n",
      " [ 0  5  0  0  0  0  0]\n",
      " [ 0  0  6  0  0  0  1]\n",
      " [ 0  0  0  4  0  0  0]\n",
      " [ 0  0  0  0 16  0  0]\n",
      " [ 0  1  0  0  0  6  1]\n",
      " [ 0  0  0  0  0  0 19]]\n",
      "Saved model + metadata to models\\fertilizer_rf.joblib\n",
      "\n",
      "Example prediction on a test row -> DAP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# train_model.py\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# ---------- Config ----------\n",
    "FULL_DATA_PATH = \"fertilizer_dataset_cleaned_final.csv\"\n",
    "TRAIN_PATH = \"train.csv\"\n",
    "TEST_PATH = \"test.csv\"\n",
    "MODEL_DIR = \"models\"\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \"fertilizer_rf.joblib\")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "def load_data():\n",
    "    # prefer pre-split files if they exist\n",
    "    if os.path.exists(TRAIN_PATH) and os.path.exists(TEST_PATH):\n",
    "        print(\"Loading existing train.csv and test.csv ...\")\n",
    "        train_df = pd.read_csv(TRAIN_PATH)\n",
    "        test_df = pd.read_csv(TEST_PATH)\n",
    "    else:\n",
    "        if not os.path.exists(FULL_DATA_PATH):\n",
    "            raise FileNotFoundError(f\"No input file found. Place your dataset as '{FULL_DATA_PATH}' or provide train.csv & test.csv.\")\n",
    "        print(f\"Loading full dataset from {FULL_DATA_PATH} and splitting into train/test ...\")\n",
    "        df = pd.read_csv(FULL_DATA_PATH)\n",
    "        train_df, test_df = train_test_split(df, test_size=TEST_SIZE, random_state=RANDOM_STATE, shuffle=True, stratify=df['fertilizer_name'] if 'fertilizer_name' in df.columns else None)\n",
    "        train_df.to_csv(TRAIN_PATH, index=False)\n",
    "        test_df.to_csv(TEST_PATH, index=False)\n",
    "        print(f\"Saved split files as {TRAIN_PATH} and {TEST_PATH}\")\n",
    "\n",
    "    print(\"Train shape:\", train_df.shape)\n",
    "    print(\"Test shape:\", test_df.shape)\n",
    "    return train_df, test_df\n",
    "\n",
    "def preprocess_train_test(train_df, test_df, target_col='fertilizer_name'):\n",
    "\n",
    "    # Standardize column names\n",
    "    train_df.columns = train_df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "    test_df.columns = test_df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "    # Identify features\n",
    "    # Assume target is 'fertilizer_name' and rest are features\n",
    "    if target_col not in train_df.columns:\n",
    "        raise ValueError(f\"Target column '{target_col}' not found in training data.\")\n",
    "\n",
    "    X_train = train_df.drop(columns=[target_col])\n",
    "    y_train = train_df[target_col].astype(str)\n",
    "\n",
    "    X_test = test_df.drop(columns=[target_col])\n",
    "    y_test = test_df[target_col].astype(str)\n",
    "\n",
    "    # List categorical columns to one-hot (common in our dataset)\n",
    "    categorical_cols = [c for c in ['soil_type', 'crop_type'] if c in X_train.columns]\n",
    "    numeric_cols = [c for c in X_train.columns if c not in categorical_cols]\n",
    "\n",
    "    # One-hot encode categorical columns using pandas.get_dummies\n",
    "    X_train_enc = pd.get_dummies(X_train, columns=categorical_cols, drop_first=False)\n",
    "    X_test_enc  = pd.get_dummies(X_test,  columns=categorical_cols, drop_first=False)\n",
    "\n",
    "    # Align columns (add any missing columns to test/train with zeros)\n",
    "    X_train_enc, X_test_enc = X_train_enc.align(X_test_enc, join='outer', axis=1, fill_value=0)\n",
    "\n",
    "    # Ensure numeric columns present and convert if needed\n",
    "    for col in numeric_cols:\n",
    "        if col in X_train_enc.columns:\n",
    "            X_train_enc[col] = pd.to_numeric(X_train_enc[col], errors='coerce').fillna(X_train_enc[col].median())\n",
    "        if col in X_test_enc.columns:\n",
    "            X_test_enc[col] = pd.to_numeric(X_test_enc[col], errors='coerce').fillna(X_train_enc[col].median())\n",
    "\n",
    "    feature_columns = list(X_train_enc.columns)\n",
    "    return X_train_enc, X_test_enc, y_train, y_test, feature_columns\n",
    "\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
    "    # Train RandomForest\n",
    "    print(\"Training RandomForestClassifier ...\")\n",
    "    clf = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nTest Accuracy: {acc:.4f}\\n\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    return clf\n",
    "\n",
    "def save_artifacts(model, feature_columns, model_path=MODEL_PATH):\n",
    "\n",
    "    artifact = {\n",
    "        \"model\": model,\n",
    "        \"feature_columns\": feature_columns,\n",
    "        \"random_state\": RANDOM_STATE\n",
    "    }\n",
    "    joblib.dump(artifact, model_path)\n",
    "    print(f\"Saved model + metadata to {model_path}\")\n",
    "\n",
    "def main():\n",
    "    train_df, test_df = load_data()\n",
    "    X_train, X_test, y_train, y_test, feature_columns = preprocess_train_test(train_df, test_df)\n",
    "    model = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "    save_artifacts(model, feature_columns)\n",
    "\n",
    "    # Example: single-row prediction demo\n",
    "    example_row = X_test.iloc[[0]]  # keep as DataFrame\n",
    "    example_pred = model.predict(example_row)[0]\n",
    "    print(\"\\nExample prediction on a test row ->\", example_pred)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64d106df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the values (press Enter for default 0 or 'Unknown'):\n",
      "\n",
      "=== Prediction Result ===\n",
      "Input: {'n': 25.0, 'p': 32.0, 'k': 65.0, 'temperature': 23.0, 'humidity': 22.0, 'moisture': 36.0, 'soil_type': '32', 'crop_type': 'ruce'}\n",
      "Predicted fertilizer: Urea\n",
      "Predicted probabilities: {'14-35-14': 0.005, '17-17-17': 0.01, 'DAP': 0.065, 'Urea': 0.92}\n"
     ]
    }
   ],
   "source": [
    "# predict_single_clean.py\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "MODEL_PATH = \"models/fertilizer_rf.joblib\"  # path where train script saved artifact\n",
    "\n",
    "def load_artifact(path=MODEL_PATH):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Model artifact not found at {path}. Run training first.\")\n",
    "    artifact = joblib.load(path)\n",
    "    return artifact\n",
    "\n",
    "def prepare_input_df(df_raw, feature_columns):\n",
    "    df = df_raw.copy()\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "    expected = ['n','p','k','temperature','humidity','moisture','soil_type','crop_type']\n",
    "    missing = [c for c in expected if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Input is missing required columns: {missing}\")\n",
    "\n",
    "    for col in ['n','p','k','temperature','humidity','moisture']:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "    for col in ['soil_type','crop_type']:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "    df_enc = pd.get_dummies(df, columns=['soil_type','crop_type'], drop_first=False)\n",
    "\n",
    "    for col in feature_columns:\n",
    "        if col not in df_enc.columns:\n",
    "            df_enc[col] = 0\n",
    "    df_enc = df_enc[feature_columns]\n",
    "    return df_enc\n",
    "\n",
    "def interactive_input():\n",
    "    print(\"Enter the values (press Enter for default 0 or 'Unknown'):\")\n",
    "    def rnum(prompt, default=0):\n",
    "        v = input(prompt).strip()\n",
    "        return float(v) if v != \"\" else default\n",
    "\n",
    "    N = rnum(\"Nitrogen (N): \")\n",
    "    P = rnum(\"Phosphorus (P): \")\n",
    "    K = rnum(\"Potassium (K): \")\n",
    "    temp = rnum(\"Temperature (Â°C): \")\n",
    "    humidity = rnum(\"Humidity (%): \")\n",
    "    moisture = rnum(\"Soil moisture (%): \")\n",
    "    soil = input(\"Soil type (Sandy/Loamy/Clayey): \").strip() or \"Sandy\"\n",
    "    crop = input(\"Crop type (Wheat/Rice/Maize/...): \").strip() or \"Wheat\"\n",
    "\n",
    "    return pd.DataFrame([{\n",
    "        'n': N, 'p': P, 'k': K,\n",
    "        'temperature': temp, 'humidity': humidity, 'moisture': moisture,\n",
    "        'soil_type': soil, 'crop_type': crop\n",
    "    }])\n",
    "\n",
    "def predict_from_df(df_input, artifact):\n",
    "    model = artifact['model']\n",
    "    feature_columns = artifact['feature_columns']\n",
    "    X = prepare_input_df(df_input, feature_columns)\n",
    "    preds = model.predict(X)\n",
    "    probs = None\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        probs_raw = model.predict_proba(X)[0]\n",
    "        classes = model.classes_\n",
    "        # Clean probabilities: round to 3 decimals and remove near-zero\n",
    "        probs = {cls: round(float(p), 3) for cls, p in zip(classes, probs_raw) if p > 0.001}\n",
    "    return preds, probs\n",
    "\n",
    "def main():\n",
    "    artifact = load_artifact(MODEL_PATH)\n",
    "    df_single = interactive_input()\n",
    "    preds, probs = predict_from_df(df_single, artifact)\n",
    "\n",
    "    print(\"\\n=== Prediction Result ===\")\n",
    "    print(\"Input:\", df_single.to_dict(orient='records')[0])\n",
    "    print(\"Predicted fertilizer:\", preds[0])\n",
    "    if probs:\n",
    "        print(\"Predicted probabilities:\", probs)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
